{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework:\n",
    "# Deep Convolutional Generative Adversarial Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of an implementation of DCGAN can be found in [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "from IPython.display import Image\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the MNIST dataset. input_data is a library that downloads the dataset and uzips it automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting fashion-mnist/data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting fashion-mnist/data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting fashion-mnist/data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting fashion-mnist/data/fashion/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('fashion-mnist/data/fashion', one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_graph = False\n",
    "if make_graph:\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.import_meta_graph('models/model-499000.cptk.meta')\n",
    "        saver.restore(sess, \"models/model-499000.cptk\")\n",
    "        writer = tf.summary.FileWriter('models/', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function performns a leaky relu activation, which is needed for the discriminator network.\n",
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    with tf.variable_scope(name):\n",
    "        f1 = 0.5 * (1 + leak)\n",
    "        f2 = 0.5 * (1 - leak)\n",
    "        return f1 * x + f2 * abs(x)\n",
    "    \n",
    "# The below functions are taken from carpdem20's implementation https://github.com/carpedm20/DCGAN-tensorflow\n",
    "# They allow for saving sample images from the generator to follow progress\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(inverse_transform(images), size, image_path)\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    return scipy.misc.imsave(path, merge(images, size))\n",
    "\n",
    "def inverse_transform(images):\n",
    "    return (images+1.)/2.\n",
    "\n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1]))\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j * h:j * h + h, i * w:i * w + w] = image\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    \n",
    "    zP = slim.fully_connected(z,4*4*256,normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='g_project',weights_initializer=initializer)\n",
    "    zCon = tf.reshape(zP,[-1,4,4,256])\n",
    "    \n",
    "    gen1 = slim.convolution2d_transpose(\\\n",
    "        zCon,num_outputs=64,kernel_size=[5,5],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='g_conv1', weights_initializer=initializer)\n",
    "    \n",
    "    gen2 = slim.convolution2d_transpose(\\\n",
    "        gen1,num_outputs=32,kernel_size=[5,5],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='g_conv2', weights_initializer=initializer)\n",
    "    \n",
    "    gen3 = slim.convolution2d_transpose(\\\n",
    "        gen2,num_outputs=16,kernel_size=[5,5],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm,\\\n",
    "        activation_fn=tf.nn.relu,scope='g_conv3', weights_initializer=initializer)\n",
    "    \n",
    "    g_out = slim.convolution2d_transpose(\\\n",
    "        gen3,num_outputs=1,kernel_size=[32,32],padding=\"SAME\",\\\n",
    "        biases_initializer=None,activation_fn=tf.nn.tanh,\\\n",
    "        scope='g_out', weights_initializer=initializer)\n",
    "    \n",
    "    return g_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task1 (13 points)\n",
    "Fill parameter for the discrimiator architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(bottom, reuse=False):\n",
    "    with slim.arg_scope([slim.fully_connected, slim.convolution2d], reuse=reuse, weights_initializer=initializer):\n",
    "        dis1 = slim.convolution2d(bottom, \n",
    "                                  num_outputs=16,\n",
    "                                  kernel_size=[32, 32],\n",
    "                                  activation_fn=lrelu,\n",
    "                                  normalizer_fn=slim.batch_norm,\n",
    "                                  scope='d_conv1')\n",
    "\n",
    "        dis2 = slim.convolution2d(dis1,\n",
    "                                  num_outputs=32,\n",
    "                                  stride=[2, 2],\n",
    "                                  kernel_size=[5, 5],\n",
    "                                  activation_fn=lrelu,\n",
    "                                  normalizer_fn=slim.batch_norm,\n",
    "                                  scope='d_conv2')\n",
    "        \n",
    "        dis3 = slim.convolution2d(dis2,\n",
    "                                  num_outputs=64,\n",
    "                                  stride=[2, 2],\n",
    "                                  kernel_size=[5, 5],\n",
    "                                  activation_fn=lrelu,\n",
    "                                  normalizer_fn=slim.batch_norm,\n",
    "                                  scope='d_conv3')\n",
    "\n",
    "        d_out = slim.fully_connected(slim.flatten(dis3), \n",
    "                                     num_outputs=1,\n",
    "                                     activation_fn=tf.nn.sigmoid,\n",
    "                                     scope='d_out')\n",
    "    \n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "z_size = 100 #Size of z vector used for generator.\n",
    "\n",
    "#This initializaer is used to initialize all the weights of the network.\n",
    "initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "\n",
    "#These two placeholders are used for input into the generator and discriminator, respectively.\n",
    "z_in = tf.placeholder(shape=[None,z_size],dtype=tf.float32) #Random vector\n",
    "real_in = tf.placeholder(shape=[None,32,32,1],dtype=tf.float32) #Real images\n",
    "\n",
    "Gz = generator(z_in) #Generates images from random z vectors\n",
    "Dx = discriminator(real_in) #Produces probabilities for real images\n",
    "Dg = discriminator(Gz,reuse=True) #Produces probabilities for generator images\n",
    "\n",
    "#These functions together define the optimization objective of the GAN.\n",
    "d_loss = -tf.reduce_mean(tf.log(Dx) + tf.log(1.-Dg)) #This optimizes the discriminator.\n",
    "g_loss = -tf.reduce_mean(tf.log(Dg)) #This optimizes the generator.\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "#The below code is responsible for applying gradient descent to update the GAN.\n",
    "trainerD = tf.train.AdamOptimizer(learning_rate=0.0002,beta1=0.5)\n",
    "trainerG = tf.train.AdamOptimizer(learning_rate=0.0002,beta1=0.5)\n",
    "d_grads = trainerD.compute_gradients(d_loss,tvars[9:]) #Only update the weights for the discriminator network.\n",
    "g_grads = trainerG.compute_gradients(g_loss,tvars[0:9]) #Only update the weights for the generator network.\n",
    "\n",
    "update_D = trainerD.apply_gradients(d_grads)\n",
    "update_G = trainerG.apply_gradients(g_grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training the network\n",
    "I strongly advise you to skip this cell and go the the next one since training will take you enormous amount of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 #Size of image batch to apply at each iteration.\n",
    "iterations = 500000 #Total number of iterations to use.\n",
    "sample_directory = './figs' #Directory to save sample images from generator in.\n",
    "model_directory = './models' #Directory to save trained model to.\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:  \n",
    "    sess.run(init)\n",
    "    for i in range(iterations):\n",
    "        zs = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32) #Generate a random z batch\n",
    "        xs,_ = mnist.train.next_batch(batch_size) #Draw a sample batch from MNIST dataset.\n",
    "        xs = (np.reshape(xs,[batch_size,28,28,1]) - 0.5) * 2.0 #Transform it to be between -1 and 1\n",
    "        xs = np.lib.pad(xs, ((0,0),(2,2),(2,2),(0,0)),'constant', constant_values=(-1, -1)) #Pad the images so the are 32x32\n",
    "        _,dLoss = sess.run([update_D,d_loss],feed_dict={z_in:zs,real_in:xs}) #Update the discriminator\n",
    "        _,gLoss = sess.run([update_G,g_loss],feed_dict={z_in:zs}) #Update the generator, twice for good measure.\n",
    "        _,gLoss = sess.run([update_G,g_loss],feed_dict={z_in:zs})\n",
    "        if i % 10 == 0:\n",
    "            print(\"Gen Loss: \" + str(gLoss) + \" Disc Loss: \" + str(dLoss))\n",
    "            z2 = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32) #Generate another z batch\n",
    "            newZ = sess.run(Gz,feed_dict={z_in:z2}) #Use new z to get sample images from generator.\n",
    "            if not os.path.exists(sample_directory):\n",
    "                os.makedirs(sample_directory)\n",
    "            #Save sample generator images for viewing training progress.\n",
    "            save_images(np.reshape(newZ[0:36],[36,32,32]),[6,6],sample_directory+'/fig'+str(i)+'.png')\n",
    "        if i % 1000 == 0 and i != 0:\n",
    "            if not os.path.exists(model_directory):\n",
    "                os.makedirs(model_directory)\n",
    "            saver.save(sess,model_directory+'/model-'+str(i)+'.cptk')\n",
    "            print(\"Saved Model at {} step\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a trained network\n",
    "Once we have a trained model saved, we may want to use it to generate new images, and explore the representation it has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_directory = './figs' #Directory to save sample images from generator in.\n",
    "model_directory = './models' #Directory to load trained model from.\n",
    "batch_size_sample = 36\n",
    "\n",
    "path = model_directory + '/model-27000.cptk'\n",
    "\n",
    "def gen_image():\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:  \n",
    "        sess.run(init)\n",
    "        #Reload the model.\n",
    "        print( 'Loading Model...')\n",
    "        saver.restore(sess, save_path=path)\n",
    "\n",
    "        zs = np.random.uniform(-1.0,1.0,size=[batch_size_sample,z_size]).astype(np.float32) #Generate a random z batch\n",
    "        newZ = sess.run(Gz,feed_dict={z_in:z2}) #Use new z to get sample images from generator.\n",
    "        if not os.path.exists(sample_directory):\n",
    "            os.makedirs(sample_directory)\n",
    "        image_path = sample_directory + '/fig' + str(i) + '.png'\n",
    "        save_images(np.reshape(newZ[0:batch_size_sample],[36,32,32]),[6,6], image_path)\n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (2 points)\n",
    "Run a couple of iterations and visualize examples generated by the generator (Could be found in ./fig folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model...\n",
      "INFO:tensorflow:Restoring parameters from ./models/model-27000.cptk\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMAAAADACAAAAAB3tzPbAAAjBklEQVR4nO1deXwURfZ/1d1z5L6B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\n2BNlM3MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename=gen_image())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (5 points)\n",
    "Evaluate discrimator accuracy in the pre-trained model on any representative subsample of fashion-minst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/model-27000.cptk\n",
      "acc=0.7271\n"
     ]
    }
   ],
   "source": [
    "sample_directory = './figs' #Directory to save sample images from generator in.\n",
    "model_directory = './models' #Directory to load trained model from.\n",
    "batch_size_sample = 36\n",
    "\n",
    "path = model_directory + '/model-27000.cptk'\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:  \n",
    "    sess.run(init)\n",
    "    saver.restore(sess, save_path=path)\n",
    "    \n",
    "    # Batch\n",
    "    n_samples = 10000\n",
    "    mnist_batch, _ = mnist.test.next_batch(n_samples)\n",
    "    mnist_batch = (np.reshape(mnist_batch,[n_samples,28,28,1])-0.5) * 2.0\n",
    "    mnist_batch = np.lib.pad(mnist_batch, ((0,0),(2,2),(2,2),(0,0)),'constant', constant_values=(-1, -1))\n",
    "    \n",
    "    # Dx\n",
    "    res = sess.run(Dx, feed_dict={real_in: mnist_batch})\n",
    "    dx_cnt = (res >= 0.5).sum()\n",
    "    \n",
    "    # Gz\n",
    "    z2 = np.random.uniform(-1.0,1.0,size=[n_samples, z_size]).astype(np.float32) #Generate a random z batch\n",
    "    gen_batch = sess.run(Gz,feed_dict={z_in:z2})\n",
    "    res = sess.run(Dx, feed_dict={real_in: gen_batch})\n",
    "    gz_cnt = (res < 0.5).sum()\n",
    "    \n",
    "    print('acc={}'.format((dx_cnt + gz_cnt) / (2 * n_samples)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
